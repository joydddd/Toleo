# Configuration file for Xeon Platinum 8380 Processor
# https://ark.intel.com/content/www/us/en/ark/products/212287/intel-xeon-platinum-8380-processor-60m-cache-2-30-ghz.html
# Total core: 40 
# 512 GB EPC 
# https://www.cpu-world.com/CPUs/Xeon/Intel-Xeon%208380.html


#include nehalem
[general]
total_cores = 40

[perf_model/core]
frequency = 2.30

[perf_model/l1_dcache]
cache_size = 48 # in KB
data_access_time = 4
tags_access_time = 1 # total latency: 5 cycles. 
associativity = 8
address_hash = mod

[perf_model/l1_icache]
cache_size = 32 # in KB
data_access_time = 4
tags_access_time = 1 # total latency: 5 cycles. 
associativity = 8

[perf_model/l2_cache]
cache_size = 1280 # in KB = 1.0 MB
data_access_time = 10
tags_access_time = 4 # total latency = 14
address_hash = mod
associative = 16

[perf_model/l3_cache]
# 60MB at 1.5MB/slice, fully associative
perfect = false
cache_block_size = 64 # in bytes
cache_size = 61440 # in KB = 60 MB shared
associativity = 16
address_hash = mod
replacement_policy = lru
# total l3 access time 21.7 ns = 51 cycle @2.3 GHz according to Intel, +L1+L2 tag access time = 5 cycle  @2.30 GHz 
# absolute L3 hit latency 63.5 cycle @2.3 GHz according to benchmark, +L1+L2 tag access time. 
data_access_time = 46
tags_access_time = 15
perf_model_type = parallel
writethrough = 0
shared_cores = 10

[perf_model/dram_directory]
# total_entries = number of entries per directory controller 
# 2 channels/MC, total 8ch, 4TB -> 500GB/ch, 1TB/cntlr
total_entries = 16777216 # 1TB/ (64B/cl) 
associativity = 16
directory_type = full_map

[perf_model/dram]
# 194 cycles, DDR4-3200, 4 memory controllers, 8 channels. 
num_controllers = 4 # 4 memory controllers
# DRAM access latency in nanoseconds. Should not include L1-LLC tag access time (20 cycles @ 2.3 GHz = 8.7 ns), directory access time,
# or network time [(cache line size + 2*{overhead=40}) / network bandwidth = 18 ns]
# Intel says 85 ns (local) and 139 ns (remote) (this is a NUMA system)
# Membench says 197 cycles @ 2.3 GHz = 85.6 ns total
latency = 58.9
# 25.6 GB/s / channel. 2 chs / MC. (theoretical)
per_controller_bandwidth = 51.2            # In GB/s
chips_per_dimm = 8
dimms_per_controller = 2

[network]
memory_model_1 = bus
memory_model_2 = bus

[network/bus] # for multi-core communication, not important
bandwidth = 67.2 # in GB/s. 11.2 GT/s per UPI link, 3 UPI Links (bi-directional) -> 11.2 GT/s x 3 x 2 = 67.2 GB/s
ignore_local_traffic = true # Memory controllers are on-chip, so traffic from core0 to dram0 does not use the QPI links

